import torch
from transformers import ViTImageProcessor, ViTForImageClassification

class AIImageDetector:
    def __init__(self):
        self.model_name = "google/vit-base-patch16-224"
        print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Ñ–æ—Ç–æ: {self.model_name}...")
        
        self.processor = ViTImageProcessor.from_pretrained(self.model_name)
        self.model = ViTForImageClassification.from_pretrained(self.model_name)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU –∏–ª–∏ CPU)
        # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–± –ø–µ—Ä–µ–Ω–æ—Å–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É –∏–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        self.model = ViTForImageClassification.from_pretrained(self.model_name)

        self.model.to(self.device)

        self.model.eval()
        print("‚úÖ –ú–æ–¥–µ–ª—å —Ñ–æ—Ç–æ –≥–æ—Ç–æ–≤–∞")

    def predict(self, image):
        """–ú–µ—Ç–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –ì–æ—Ç–æ–≤–∏–º –∫–∞—Ä—Ç–∏–Ω–∫—É
        inputs = self.processor(images=image, return_tensors="pt")
        
        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Ç–æ –∂–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ, —á—Ç–æ –∏ –º–æ–¥–µ–ª—å
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        probs = torch.nn.functional.softmax(logits, dim=-1)
        
        # –î–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞–º –ø—Ä–æ—Å—Ç–æ –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∫–∞–∫–æ–π-—Ç–æ —Å–∫–æ—Ä. 
        # –í —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞—Ö –ª–æ–≥–∏–∫–∞ —Å–ª–æ–∂–Ω–µ–µ, –Ω–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã API —Å–¥–µ–ª–∞–µ–º —Ç–∞–∫:
        ai_prob = probs[0][0].item() # –ü—Ä–∏–º–µ—Ä –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        
        return {
            "real_probability": 1.0 - ai_prob,
            "ai_probability": ai_prob
        }